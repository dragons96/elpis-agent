# Define a model configuration called CHAT
# {MODEL_NAME}_BASE_URL is the base url of the model provider
CHAT_BASE_URL=https://api.openai.com/v1
# {MODEL_NAME}_API_KEY is the api key of the model provider, if not set, delete it
CHAT_API_KEY=
# {MODEL_NAME}_MODEL is the model name of the model provider
CHAT_MODEL=gpt4.1
# {MODEL_NAME}_MODEL_PROVIDER is the model provider name, allow: openai, ollama
CHAT_MODEL_PROVIDER=openai
# {MODEL_NAME}_MODEL_TYPE is the model type, allow: chat, embedding
CHAT_MODEL_TYPE=chat
# {MODEL_NAME}_TEMPERATURE is the temperature of the model provider
CHAT_TEMPERATURE=0.3

# Define a model configuration called EMBEDDING
EMBEDDING_BASE_URL=http://127.0.0.1:11434
EMBEDDING_MODEL=
EMBEDDING_MODEL_PROVIDER=ollama
EMBEDDING_MODEL_TYPE=embedding
EMBEDDING_TEMPERATURE=0.3

# Chat model using CHAT model configuration
CHAT_MODEL_KEY_PREFIX=CHAT
# The configuration of embedding models using EMBEDDING models, if not set, please delete it, codebase is unsed when embedding is not set.
#EMBEDDING_MODEL_KEY_PREFIX=EMBEDDING

SYSTEM_PROMPT=

# Memory type, allow: [memory, sqlite], if not set, delete it and not used checkpointer.
CHECKPOINTER=memory

# MCP file path, default : ./mcp.json
# {
#   "mcpServers": {
#
#   }
# }
MCP_FILE_PATH=mcp.json
